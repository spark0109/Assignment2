{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Q1MwNryFaknb"
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "\n",
    "diabetes=load_diabetes()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "diabetes의 data를 df_X에, target을 df_y에 저장해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_X=diabetes.data\n",
    "df_y=diabetes.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_X에 있는 값들을 numpy array로 변환해서 저장해주세요.\n",
    "df_y에 있는 값들을 numpy array로 변환해서 저장해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442, 10)\n"
     ]
    }
   ],
   "source": [
    "print(df_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(442,)\n"
     ]
    }
   ],
   "source": [
    "print(df_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "입력 데이터 개수에 맞는 가중치 W와 b를 준비해주세요.\n",
    "모델 함수를 구현해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "X = np.array(df_X)\n",
    "y = np.array(df_y)\n",
    "W = np.random.rand(10)\n",
    "b = np.random.rand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, W, b):\n",
    "    predictions = 0\n",
    "    for i in range(10):\n",
    "        predictions += X[:, i] * W[i]\n",
    "    predictions += b\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "손실함수를 MSE 함수로 정의해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MSE(a, b):\n",
    "    mse = ((a - b) ** 2).mean()  # 두 값의 차이의 제곱의 평균\n",
    "    return mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(X, W, b, y):\n",
    "    predictions = model(X, W, b)\n",
    "    L = MSE(predictions, y)\n",
    "    return L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기울기를 계산하는 gradient 함수를 구현해주세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient(X, W, b, y):\n",
    "    N = len(W)\n",
    "    \n",
    "    y_pred = model(X, W, b)\n",
    "\n",
    "    dW = 1/N * 2 * X.T.dot(y_pred - y)\n",
    "\n",
    "    db = 2 * (y_pred - y).mean()\n",
    "    return dW, db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "학습률, learning rate 를 설정해주세요\n",
    "만약 학습이 잘 되지 않는다면 learning rate 값을 한번 여러 가지로 설정하며 실험해 보세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 10 : Loss 28817.6222\n",
      "Iteration 20 : Loss 28722.7587\n",
      "Iteration 30 : Loss 28628.2651\n",
      "Iteration 40 : Loss 28534.1400\n",
      "Iteration 50 : Loss 28440.3819\n",
      "Iteration 60 : Loss 28346.9893\n",
      "Iteration 70 : Loss 28253.9609\n",
      "Iteration 80 : Loss 28161.2951\n",
      "Iteration 90 : Loss 28068.9905\n",
      "Iteration 100 : Loss 27977.0458\n",
      "Iteration 110 : Loss 27885.4594\n",
      "Iteration 120 : Loss 27794.2300\n",
      "Iteration 130 : Loss 27703.3562\n",
      "Iteration 140 : Loss 27612.8365\n",
      "Iteration 150 : Loss 27522.6695\n",
      "Iteration 160 : Loss 27432.8538\n",
      "Iteration 170 : Loss 27343.3882\n",
      "Iteration 180 : Loss 27254.2710\n",
      "Iteration 190 : Loss 27165.5011\n",
      "Iteration 200 : Loss 27077.0769\n",
      "Iteration 210 : Loss 26988.9972\n",
      "Iteration 220 : Loss 26901.2606\n",
      "Iteration 230 : Loss 26813.8657\n",
      "Iteration 240 : Loss 26726.8112\n",
      "Iteration 250 : Loss 26640.0957\n",
      "Iteration 260 : Loss 26553.7178\n",
      "Iteration 270 : Loss 26467.6763\n",
      "Iteration 280 : Loss 26381.9699\n",
      "Iteration 290 : Loss 26296.5971\n",
      "Iteration 300 : Loss 26211.5566\n",
      "Iteration 310 : Loss 26126.8472\n",
      "Iteration 320 : Loss 26042.4676\n",
      "Iteration 330 : Loss 25958.4163\n",
      "Iteration 340 : Loss 25874.6922\n",
      "Iteration 350 : Loss 25791.2940\n",
      "Iteration 360 : Loss 25708.2203\n",
      "Iteration 370 : Loss 25625.4698\n",
      "Iteration 380 : Loss 25543.0414\n",
      "Iteration 390 : Loss 25460.9336\n",
      "Iteration 400 : Loss 25379.1453\n",
      "Iteration 410 : Loss 25297.6752\n",
      "Iteration 420 : Loss 25216.5220\n",
      "Iteration 430 : Loss 25135.6845\n",
      "Iteration 440 : Loss 25055.1613\n",
      "Iteration 450 : Loss 24974.9514\n",
      "Iteration 460 : Loss 24895.0534\n",
      "Iteration 470 : Loss 24815.4660\n",
      "Iteration 480 : Loss 24736.1882\n",
      "Iteration 490 : Loss 24657.2186\n",
      "Iteration 500 : Loss 24578.5560\n",
      "Iteration 510 : Loss 24500.1992\n",
      "Iteration 520 : Loss 24422.1471\n",
      "Iteration 530 : Loss 24344.3983\n",
      "Iteration 540 : Loss 24266.9517\n",
      "Iteration 550 : Loss 24189.8061\n",
      "Iteration 560 : Loss 24112.9604\n",
      "Iteration 570 : Loss 24036.4132\n",
      "Iteration 580 : Loss 23960.1636\n",
      "Iteration 590 : Loss 23884.2101\n",
      "Iteration 600 : Loss 23808.5518\n",
      "Iteration 610 : Loss 23733.1874\n",
      "Iteration 620 : Loss 23658.1157\n",
      "Iteration 630 : Loss 23583.3357\n",
      "Iteration 640 : Loss 23508.8461\n",
      "Iteration 650 : Loss 23434.6459\n",
      "Iteration 660 : Loss 23360.7338\n",
      "Iteration 670 : Loss 23287.1087\n",
      "Iteration 680 : Loss 23213.7695\n",
      "Iteration 690 : Loss 23140.7150\n",
      "Iteration 700 : Loss 23067.9442\n",
      "Iteration 710 : Loss 22995.4559\n",
      "Iteration 720 : Loss 22923.2490\n",
      "Iteration 730 : Loss 22851.3224\n",
      "Iteration 740 : Loss 22779.6749\n",
      "Iteration 750 : Loss 22708.3055\n",
      "Iteration 760 : Loss 22637.2131\n",
      "Iteration 770 : Loss 22566.3965\n",
      "Iteration 780 : Loss 22495.8548\n",
      "Iteration 790 : Loss 22425.5867\n",
      "Iteration 800 : Loss 22355.5912\n",
      "Iteration 810 : Loss 22285.8673\n",
      "Iteration 820 : Loss 22216.4138\n",
      "Iteration 830 : Loss 22147.2298\n",
      "Iteration 840 : Loss 22078.3140\n",
      "Iteration 850 : Loss 22009.6656\n",
      "Iteration 860 : Loss 21941.2833\n",
      "Iteration 870 : Loss 21873.1662\n",
      "Iteration 880 : Loss 21805.3132\n",
      "Iteration 890 : Loss 21737.7233\n",
      "Iteration 900 : Loss 21670.3954\n",
      "Iteration 910 : Loss 21603.3285\n",
      "Iteration 920 : Loss 21536.5216\n",
      "Iteration 930 : Loss 21469.9736\n",
      "Iteration 940 : Loss 21403.6835\n",
      "Iteration 950 : Loss 21337.6503\n",
      "Iteration 960 : Loss 21271.8729\n",
      "Iteration 970 : Loss 21206.3505\n",
      "Iteration 980 : Loss 21141.0819\n",
      "Iteration 990 : Loss 21076.0661\n",
      "Iteration 1000 : Loss 21011.3022\n"
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "\n",
    "for i in range(1, 1001):\n",
    "    dW, db = gradient(X, W, b, y)\n",
    "    W -= LEARNING_RATE * dW\n",
    "    b -= LEARNING_RATE * db\n",
    "    L = loss(X, W, b, y)\n",
    "    losses.append(L)\n",
    "    if i % 10 == 0:\n",
    "        print('Iteration %d : Loss %0.4f' % (i, L))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'reference: https://yhyun225.tistory.com/11'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''reference: https://yhyun225.tistory.com/11'''"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
